\section{Applications and Evaluation}
\label{sec:application}
We evaluate our formalization and implementation of the SFT product operation across two key application domains: string sanitization and string replacement in string solving. These case studies highlight the practical value of our certified SFT formalization in real-world scenarios.
\subsection{Sanitizer}

Sanitizers are crucial for preventing security vulnerabilities such as cross-site scripting (XSS) attacks by ensuring that user inputs are properly encoded before rendering in web browsers.

Figure \ref{lst-html-encode} presents a C\# code snippet implementing an HTML encoding function for Anti-XSS. This function iterates through each character in the input string and encodes characters that are unsafe for HTML rendering.

\begin{figure}[hbt!]
\begin{lstlisting}[language={[Sharp]C}]
static string EncodeHtml(string t)
{
  if (t == null) { return null; }
  if (t.Length == 0) {
    return string.Empty;
  }
  StringBuilder builder = new
    StringBuilder("", t.Length * 2);
  foreach (char c in t) {
    if ((((c > ''') && (c < '{')) |$\mid\mid$|
         ((c > '@') && (c < '['))) |$\mid\mid$|
         (((c == ' ') || ((c > '/') && (c < ':'))) |$\mid\mid$|
         (((c == '.') || (c == ',')) |$\mid\mid$|
         ((c == '-') || (c == '_'))))) {
          builder.Append(c);
      }
      else {
          builder.Append("&#" +
          ((int) c).ToString() + ";");
      }
  }
  return builder.ToString();
}
\end{lstlisting}
\caption{C\# Code for AntiXSS.EncodeHtml version 2.0.}
\label{lst-html-encode}
\end{figure}

Figure \ref{fig:html-sanitizer-sft} illustrates the SFT representation of the HTML encoding sanitizer function.
 The set of safe characters is defined as $\texttt{safe\_chars} = [\texttt{' '}, \texttt{','}, \texttt{'.'}, \texttt{'-'}, \texttt{'\_'}] \cup [\texttt{'0'}-\texttt{'9'}] \cup [\texttt{'A'}-\texttt{'Z'}] \cup [\texttt{'a'}-\texttt{'z'}]$, which can be efficiently represented using the interval algebra we formalized. Unsafe characters are transformed using the encoding function $\texttt{encode}(c) = \texttt{``\&\#''} + \texttt{toString}(\texttt{ord}(c)) + \texttt{``;''}$. When the alphabet is set to Unicode $[\mathtt{0x0000}, \mathtt{0x10FFFF}]$, the complement $\neg\texttt{safe\_chars}$ represents all Unicode characters outside the safe set, which can also be efficiently represented using our formalized interval operations. \texttt{id}, \texttt{encode}, and $\lambda \_.\varepsilon$ are the identity, encode of unsafe characters, and empty word output functions, respectively.
\begin{figure}[htbp]
\centering
\begin{tikzpicture}[shorten >=1pt, node distance=2.5cm, on grid, auto]
  % States
  \node[state, initial, accepting] (q0) {$q_0$};
  \node[state] (q1) [right=3.5cm of q0] {$q_1$};
  \node[state] (q2) [below=of q0] {$q_2$};
  
  \path[->] 
    % Transition for safe characters
    (q0) edge[bend left=20] node[above,midway=1] {$\texttt{safe\_chars}, \texttt{id}$} (q1)
    % Transition for unsafe characters  
    (q0) edge[bend right=20] node[left,midway] {$\neg\texttt{safe\_chars}, \texttt{encode}$} (q2)
    % Epsilon transitions back to q0
    (q1) edge[bend left=30] node[below,midway] {$\varepsilon, \lambda \_.\varepsilon$} (q0)
    (q2) edge[bend right=20] node[right,midway] {$\varepsilon, \lambda \_.\varepsilon$} (q0);
\end{tikzpicture}
\caption{SFT representation of the HTML encoding sanitizer function.}
\label{fig:html-sanitizer-sft}
\end{figure}

We first evaluate the performance of our SFT product operation by computing the product of the HTML encoding sanitizer shown in Figure \ref{fig:html-sanitizer-sft} with SFAs constructed from randomly generated Unicode sequences. This product represents the sanitization result by the SFT for the input sequence. The experimental evaluation was conducted on a laptop equipped with an Apple M4 processor and 24 GB of memory, with a one-minute time limit imposed for each test.



\begin{figure}
\centering
\includegraphics[scale=0.45]{benchmark_loglog.pdf}
\caption{Experimental results for the sanitizer product}
\label{fig:benchmark-results}
\end{figure}

Figure \ref{fig:benchmark-results} demonstrates the scalability characteristics of our SFT product implementation. The computation requires approximately 1 second for 100,000-character inputs and 10 seconds for 1,000,000-character inputs. These performance metrics confirm that our certified implementation maintains computational efficiency suitable for practical string processing applications at scale.

Beyond performance evaluation, our SFT formalization also supports the formal verification of string sanitizer's safety property. A sanitizer transforms user inputs into safe outputs, ensuring that the result contains no unsafe characters. However, sanitizers—like any other programs—are error-prone. Manual reviews or testing alone are often insufficient to guarantee their correctness.

Based on our formalization, we can verify sanitizers by modeling the sanitizer as an SFT and the user input as an SFA. We can also model potential attacks as SFAs that accept unsafe strings. Formally speaking, Let $\mathcal{T}$ be an SFT, $\mathcal{I}$ is the possible user inputs modeled by an SFA, and $\mathcal{A}$ is the attack SFA that accepts unsafe strings. The santizer correctness checking against the attack is to check whether the intersection of the product $\mathcal{T} \times \mathcal{I}$ and the attack SFA $\mathcal{A}$ is empty, i.e., $(\mathcal{T} \times \mathcal{I}) \cap \mathcal{A} = \emptyset$.

Moreover, santizers are usually used in combination with other sanitizers to ensure comprehensive safety. For example, the HTML encoding sanitizer can be combined with a string trimming operation to remove leading and trailing whitespace characters. For this kind of sanitizer composition, it can be modeled by our SFT product as well. Let $\mathcal{T}_1$ and $\mathcal{T}_2$ correspond to two sanitizers, and $\mathcal{T}_1$ is applied before $\mathcal{T}_2$. What we need to check is $(\mathcal{T}_2 \times (\mathcal{T}_1 \times \mathcal{I})) \cap \mathcal{A} = \emptyset$.




\begin{table}[h]
  \centering
  \small
  \caption{Sanitizer verfication result}
  \label{tab:sanitizer_attack}
  \setlength{\tabcolsep}{4pt} % Reduced column gap
  \begin{tabular}{p{2.2cm}ll} % Increased width for automatic line break
    \toprule
    \textbf{Attack Model} & \textbf{Verfication Result} & \textbf{Size} \\
    \midrule
    attack\_html           & GA HtmlEscape: \textbf{Unsafe} & 1/6\\
                           & Trim + GA HtmlEscape: \textbf{Safe} & 4/12 \\
                           & escapeString: \textbf{Unsafe} & 1/11 \\
                           & Trim + escapeString: \textbf{Safe} & 4/17 \\
                           & Trim + OWASP HTMLEncode: \textbf{Safe} & 4/18 \\
    \midrule
    attack\_javascript     & GA HtmlEscape + GA PreEscape + & 3/20 \\
                           &  gaSnippetesc: \textbf{safe} & \\
    \midrule
    attack\_json           & Trim + GA JSONESc : \textbf{Safe} & 4/16\\
    \midrule
    attack\_xml            & Trim + GA XMLEsc: \textbf{safe} & 4/16\\
    \midrule
    attack\_ccs            & Trim + GA CleanseCSS : \textbf{Safe} & 25/46\\
    \bottomrule
  \end{tabular}
\end{table}

Table \ref{tab:sanitizer_attack} summarizes the verification results for various sanitizers against different attack models. The first column lists the attack models, the second column indicates whether the sanitizer is classified as safe or unsafe with respect to the attack, and the third column reports the size of the transducers used in the verification, given as [number of states/number of transitions]. For composed SFTs, the size reflects the total number of states and transitions across all SFTs.

We evaluate a range of attack models for HTML, JavaScript, JSON, XML, and CSS. Listing \ref{lst-css-attack} shows the CSS attack model, which is used to verify the corresponding sanitizer. The attack model includes comments, declaration breakers, and known dangerous tokens such as \textbf{expression(}, \textbf{@import}, \textbf{behavior:}, \textbf{-moz-binding}, and \textbf{url(} (unless the URL is separately validated).
These are unsafe and undesired strings in CSS contexts.
Sanitizers include GA HtmlEscape, GA JSONEscape, GA XMLEscape, escapeString, and CleanseCSS, where "GA" means from Google Analytics. Sanitizers are often composed with preprocessing steps such as Trim, which removes leading and trailing whitespace characters. As shown in the table, GAHtmlEscape and escapeString are unsafe with respect to the HTML attack model without preprocessing, but become safe when combined with Trim. The \textbf{Size} column demonstrates the succinctness of SFTs in modeling real-world transducers. We did not list the execution time of verification because all of them are quite efficent with less than 0.02 second to finish the verificaiton.




\begin{lstlisting}[language={}, caption={CSS attack model for sanitizer verification}, captionpos=b, label={lst-css-attack}, float=htbp]
|$\Sigma$|* ( / \* [\s\S]*? \*/
  |$\mid$| ; |$\mid$| \{ |$\mid$| \}
  |$\mid$| [eE][xX][pP][rR][eE][sS][sS][iI]
    [oO][nN]\s*\(
  |$\mid$| @\s*[iI][mM][pP][oO][rR][tT]
  |$\mid$| [bB][eE][hH][aA][vV][iI][oO][rR]\s*:
  |$\mid$| -\s*[mM][oO][zZ]-\s*[bB][iI][nN]
    [dD][iI][nN][gG]
  |$\mid$| (?!allowUrl) [uU][rR][lL]\s*\(
 ) |$\Sigma$|*
\end{lstlisting}

%\subsection{Modeling the Replacement Operation}

\subsection{Applications to String Replacement}

The string replacement, denoted as
$\texttt{replace}(\texttt{str}, \texttt{pattern}, \newline\texttt{replacement}, \texttt{flag})$, is a fundamental string transformation accepting four parameters:
(1) $\texttt{str}$: The input string to be transformed.
(2) $\texttt{pattern}$: A regular expression defining the matching pattern.
(3) $\texttt{replacement}$: The string that replaces matched substrings.
(4) $\texttt{flag}=s/g$: The replacement mode flag, where $s$ denotes single first occurrence replacement and $g$ denotes all occurrences replacement operation.

% The operation's semantics is to replace the first occurrence (or all occurrences) of any substring $s'$ in \texttt{str} that matches $\texttt{pattern}$ with \texttt{replacement}.

To illustrate how SFTs model this operation, consider $\texttt{replace}(s, \texttt{/[0-9]+/},~$\texttt{NUM}$,~\texttt{flag})$. We construct the corresponding SFT by the following three steps.

\begin{enumerate}
  \item Construct an SFA recognizing the pattern $\texttt{/[0-9]+/}$ and transform it into an SFT by augmenting each transition with output function "$\lambda x.~\texttt{None}$" that produces the empty string.
  \item Construct an SFA accepting the replacement string \texttt{NUM} and convert it to an SFT by
  replacing each transtion in the SFA $(q, c, q')$ with
  $(q, (\texttt{None},~\lambda \_.~c ), q')$.
  \item Compose the two SFTs by connecting the accepting state of the pattern-matching SFT to the initial state of the replacement-generating SFT via $\varepsilon$-transitions.
\end{enumerate}


%\noindent\emph{Step 1.}
%Figure \ref{fig-snfa-pattern} illustrates the construction of the pattern-matching component. The left side shows the SFA that recognizes the regular expression $\texttt{/[0-9]+/}$, while the right side presents its transformation into an SFT. This transformation is achieved by augmenting each transition with the output function $\texttt{f} = \lambda x.~\texttt{None}$, which consistently produces the empty string, effectively "consuming" the matched digits without generating output.

Figure \ref{fig-rearranged-automata} presents the complete SFT construction, obtained by composing the pattern-matching SFT generated from \texttt{/[0-9]+/}  with the replacement-generating SFT generated from \texttt{NUM}.

\begin{figure}[h] \centering
  \begin{tikzpicture}[shorten >=1pt, node distance=2cm, auto]
    % Second automaton from the first figure
    \node[state, initial] (q0') {$q_0'$}; 
    \node[state] (q1') [right=of q0'] {$q_1'$}; 
  
     \path[->] 
     (q0') edge [bend left] node {\texttt{[0-9]}, $\lambda~x.~\texttt{None}$} (q1')
     (q1') edge [loop right] node {\texttt{[0-9]}, $\lambda~x.~\texttt{None}$} (q1');
  
    % Second automaton from the second figure
    \node[state] (q0'') [below=1cm of q1'] {$q_0''$}; 
    \node[state] (q1'') [right=of q0''] {$q_1''$}; 
    \node[state, accepting] (q3'') [below=1cm of q0''] {$q_3''$}; 
    \node[state] (q2'') [right=of q3''] {$q_2''$}; 
  
    \path[->] 
    (q0'') edge node {\texttt{None}, $\lambda\_.\texttt{N}$} (q1'')
    (q1'') edge [bend left=5] node[left] {\texttt{None}, $\lambda\_.\texttt{U}$} (q2'')
    (q2'') edge node {\texttt{None}, $\lambda\_.\texttt{M}$} (q3'')
    (q1') edge [bend right=30] node {\texttt{None}, $\lambda x.~\texttt{None}$} (q0'');
  \end{tikzpicture}
  \caption{The SFT for the replacement operation $\texttt{replace}(s,\texttt{/[0-9]+/}, \texttt{NUM})$}
  \label{fig-rearranged-automata}
  \end{figure}

  We can extend the above construction to model both replace-first and replace-all for XSS attack verification. In this paper, we only illustrate the construction of replace-all in Figure \ref{fig:replace-all}. The SFT $\mathcal{T}_2$ combines pattern matching and replacement using the construction just described. The SFT $\mathcal{T}_1$ matches strings that do not contain any substrings matching the pattern. Two $\varepsilon$-transitions connect these components: one from $\mathcal{T}_1$'s accepting state to $\mathcal{T}_2$'s initial state, and another from $\mathcal{T}_2$'s accepting state back to $\mathcal{T}_1$'s initial state. This cyclic structure enables the replace-all operation by repeatedly applying pattern replacement until no more matches exist in the input string. Replace-first modeling has no transtion from $\mathcal{T}_2$'s accepting state back to $\mathcal{T}_1$'s initial state.




\begin{figure}[htbp]
\centering
\begin{tikzpicture}[node distance=2cm, state/.style={circle, draw, minimum size=0.8cm}]
  % First SFT rectangle
  \node[draw, rectangle, minimum width=5.2cm, minimum height=2.1cm] (sft1-box) {};
  \node[above=0.1cm of sft1-box.north] {\textbf{SFT} $\mathcal{T}_1$ (Non-matching)};
  
  % States inside first SFT
  \node[state, initial] (p0) at ([xshift=-0.8cm]sft1-box.center) {$p_0$};
  \node[state, accepting] (p1) at ([xshift=1.8cm]sft1-box.center) {$p_1$};
  \path[->] (p0) edge[above] node {\shortstack{$\neg\texttt{pattern},$ \\ $\lambda x.x$}} (p1);
  
  % Second SFT rectangle
  \node[draw, rectangle, minimum width=5.2cm, minimum height=2.1cm, below=1.5cm of sft1-box] (sft2-box) {};
  \node[below=0.1cm of sft2-box.south] {\textbf{SFT} $\mathcal{T}_2$ (Matching)};
  
  % States inside second SFT
  \node[state, initial] (s0) at ([xshift=-0.8cm]sft2-box.center) {$s_0$};
  \node[state, accepting] (s1) at ([xshift=2cm]sft2-box.center) {$s_1$};
  \path[->] (s0) edge[above] node {\shortstack{$\texttt{pattern},$ \\ $\texttt{replacement}$}} (s1);
  
  % Epsilon transition from accepting state of first SFT to initial state of second SFT
  \path[->] (p1) edge[bend right=30] node[left] {\shortstack{$\varepsilon$, $\lambda\varepsilon$}} (s0);
  
  % Epsilon transition from accepting state of second SFT to initial state of first SFT
  \path[->] (s1) edge[bend right=30] node[right] {\shortstack{$\varepsilon$, $\lambda\varepsilon$}} (p0);
  
\end{tikzpicture}
\caption{The modeling of replace all operation.}
\label{fig:replace-all}
\end{figure}



% \begin{figure}[h] \centering
% \begin{tikzpicture}[shorten >=1pt, node distance=1.8cm, auto]
%   % Left: SFA for [0-9]+ (vertical)
%   \node[state, initial] (q0)   {$q_0$}; 
%   \node[state, accepting, below=of q0] (q1) {$q_1$}; 

%    \path[->] 
%    (q0) edge [bend left=20] node[right] {\texttt{[0-9]}} (q1)
%    (q1) edge [loop below] node {\texttt{[0-9]}} (q1);

%   % Right: SFT for [0-9]+ (vertical)
%   \node[state, initial, right=4cm of q0] (q0') {$q_0'$}; 
%   \node[state, accepting, below=of q0'] (q1') {$q_1'$}; 

%    \path[->] 
%    (q0') edge [bend left=20] node[right] {\texttt{[0-9]},$\texttt{f}$} (q1')
%    (q1') edge [loop below] node {\texttt{[0-9]},$\texttt{f}$} (q1');
% \end{tikzpicture}
% \caption{Corresponding SFA and SFT for \texttt{/[0-9]+/}}
% \label{fig-snfa-pattern}
% \end{figure}

% \noindent\emph{Step 2.}
% Figure \ref{fig-snfa-replacement} depicts the automata for the replacement string "\texttt{NUM}". The left side shows the SFA that accepts this constant string, while the right side presents its SFT transformation. The transformation employs an indexed output function \texttt{g} that emits characters of the replacement string sequentially:
% \[
% \texttt{g} = \lambda~i~x.~\texttt{match}~i~\texttt{with}~
% \begin{cases}
% 1 \mapsto [(78, 78)] & \text{(ASCII for 'N')} \\
% 2 \mapsto [(85, 85)] & \text{(ASCII for 'U')} \\
% 3 \mapsto [(77, 77)] & \text{(ASCII for 'M')} \\
% \_ \mapsto \texttt{None}
% \end{cases}
% \]
% This function maps transition indices to their corresponding character outputs, using ASCII codes to represent the string "\texttt{NUM}" character by character.


% \begin{figure}[h] \centering
% \begin{tikzpicture}[shorten >=1pt, node distance=2cm, auto]
%   % SFA for "NUM" (top)
%   \node[state, initial above] (q0)   {$q_0$}; 
%   \node[state] (q1) [right=1cm of q0] {$q_1$}; 
%   \node[state] (q2) [below=1cm of q1] {$q_2$}; 
%   \node[state, accepting] (q3) [below=1cm of q0] {$q_3$}; 

%   \path[->] 
%   (q0) edge node {\texttt{N}} (q1)
%   (q1) edge node {\texttt{U}} (q2)
%   (q2) edge node {\texttt{M}} (q3);

%   % SFT for "NUM" (right)
%   \node[state, initial above] (q0') [right=1.5cm of q1] {$q_0'$}; 
%   \node[state] (q1') [right=of q0'] {$q_1'$}; 
%   \node[state] (q2') [below=1cm of q1'] {$q_2'$}; 
%   \node[state, accepting] (q3') [below=1cm of q0'] {$q_3'$}; 

%   \path[->] 
%   (q0') edge node {\texttt{None}, \texttt{(g 1)}} (q1')
%   (q1') edge node[left] {\texttt{None}, \texttt{(g 2)}} (q2')
%   (q2') edge node[below] {\texttt{None}, \texttt{(g 3)}} (q3');
% \end{tikzpicture}
% \caption{Corresponding SFA and SFT for "\texttt{NUM}"}
% \label{fig-snfa-replacement}
% \end{figure}


% \noindent\emph{Step 3.}
% Figure \ref{fig-rearranged-automata} presents the complete SFT construction, obtained by composing the pattern-matching SFT (Fig. \ref{fig-snfa-pattern}) with the replacement-generating SFT (Fig. \ref{fig-snfa-replacement}). The composition process involves connecting the two SFTs by adding $\varepsilon$-transitions (labeled with "\texttt{None}, \texttt{f}") from each accepting state of the pattern-matching SFT to the initial state of the replacement-generating SFT.


% \begin{figure}[h] \centering
%   \begin{tikzpicture}[shorten >=1pt, node distance=2cm, auto]
%     % Second automaton from the first figure
%     \node[state, initial] (q0') {$q_0'$}; 
%     \node[state] (q1') [right=of q0'] {$q_1'$}; 
  
%      \path[->] 
%      (q0') edge [bend left] node {\texttt{[0-9]}, $\texttt{f}$} (q1')
%      (q1') edge [loop right] node {\texttt{[0-9]}, $\texttt{f}$} (q1');
  
%     % Second automaton from the second figure
%     \node[state] (q0'') [below=1cm of q1'] {$q_0''$}; 
%     \node[state] (q1'') [right=of q0''] {$q_1''$}; 
%     \node[state, accepting] (q3'') [below=1cm of q0''] {$q_3''$}; 
%     \node[state] (q2'') [right=of q3''] {$q_2''$}; 
  
%     \path[->] 
%     (q0'') edge node {\texttt{None}, \texttt{(g 1)}} (q1'')
%     (q1'') edge [bend left=5] node[left] {\texttt{None}, \texttt{(g 2)}} (q2'')
%     (q2'') edge node {\texttt{None}, \texttt{(g 3)}} (q3'')
%     (q1') edge [bend right=30] node {\texttt{None}, \texttt{f}} (q0'');
%   \end{tikzpicture}
%   \caption{The SFT for the replacement operation \\ $\texttt{replace}(s, \texttt{/[0-9]+/}, \text{``NUM''})$}
%   \label{fig-rearranged-automata1}
%   \end{figure}

%   We can extend the above construction to model both singleton and replace-all operations. In this paper, we only illustrate the construction of replace-all in Figure \ref{fig:replace-all}. The SFT $\mathcal{T}_2$ combines pattern matching and replacement using the construction just described. The SFT $\mathcal{T}_1$ matches strings that do not contain any substrings matching the pattern. Two $\varepsilon$-transitions connect these components: one from $\mathcal{T}_1$'s accepting state to $\mathcal{T}_2$'s initial state, and another from $\mathcal{T}_2$'s accepting state back to $\mathcal{T}_1$'s initial state. This cyclic structure enables the replace-all operation by repeatedly applying pattern replacement until no more matches exist in the input string.


%   Having constructed the SFT, we can now compute the forward image of the replacement operation. Consider the string constraint $s' = \texttt{replace}(s,~\texttt{/[0-9]+/},~\text{"}\texttt{NUM}\text{"})$, where we aim to characterize the possible values of $s'$. Let $\mathcal{T}$ denote the constructed SFT modeling the replacement operation, and let $\mathcal{A}$ be the SFA representing the domain of possible values for the input string $s$. The forward image of this replacement operation is given by the product $\mathcal{T} \times \mathcal{A}$, which precisely captures the set of all possible output strings that can be produced by applying the replacement operation to any input string accepted by $\mathcal{A}$.
%   Our string solver uses this forward image to do forward propagation for further string solving.


% \begin{figure}[htbp]
% \centering
% \begin{tikzpicture}[node distance=2cm, state/.style={circle, draw, minimum size=0.8cm}]
%   % First SFT rectangle
%   \node[draw, rectangle, minimum width=5.2cm, minimum height=2.1cm] (sft1-box) {};
%   \node[above=0.1cm of sft1-box.north] {\textbf{SFT} $\mathcal{T}_1$ (Non-matching)};
  
%   % States inside first SFT
%   \node[state, initial] (p0) at ([xshift=-0.8cm]sft1-box.center) {$p_0$};
%   \node[state, accepting] (p1) at ([xshift=1.8cm]sft1-box.center) {$p_1$};
%   \path[->] (p0) edge[above] node {\shortstack{$\neg\texttt{pattern},$ \\ $\lambda x.x$}} (p1);
  
%   % Second SFT rectangle
%   \node[draw, rectangle, minimum width=5.2cm, minimum height=2.1cm, below=1.5cm of sft1-box] (sft2-box) {};
%   \node[below=0.1cm of sft2-box.south] {\textbf{SFT} $\mathcal{T}_2$ (Matching)};
  
%   % States inside second SFT
%   \node[state, initial] (s0) at ([xshift=-0.8cm]sft2-box.center) {$s_0$};
%   \node[state, accepting] (s1) at ([xshift=2cm]sft2-box.center) {$s_1$};
%   \path[->] (s0) edge[above] node {\shortstack{$\texttt{pattern},$ \\ $\texttt{replacement}$}} (s1);
  
%   % Epsilon transition from accepting state of first SFT to initial state of second SFT
%   \path[->] (p1) edge[bend right=30] node[left] {\shortstack{$\varepsilon$, $\lambda\varepsilon$}} (s0);
  
%   % Epsilon transition from accepting state of second SFT to initial state of first SFT
%   \path[->] (s1) edge[bend right=30] node[right] {\shortstack{$\varepsilon$, $\lambda\varepsilon$}} (p0);
  
% \end{tikzpicture}
% \caption{The modeling of replace all operation.}
% \label{fig:replace-all1}
% \end{figure}



We evaluate our SFT-based replacement operation by extending CertiStr \cite{cpp/KanLRS22}, a certified string solver that previously supported only basic string operations: concatenation and regular constraints. The original CertiStr was incapable of verifying any XSS attack due to the lack of support for transducers and replacement operations.
CertiStr employs a forward-propagation approach to solve string constraints, which requires computing the forward image of string operations. Our SFT product operation provides an exact forward image computation for replacement operations, enabling seamless integration of replacement functionality into CertiStr's solving framework.
The OCaml code of the SFT implementation is extracted from our Isabelle formalization using Isabelle's extraction mechanism, ensuring that the core solving algorithm of CertiStr remains certified.

By incorporating our SFT-based modeling of replacement, we develop CertiStrR—an
extended string solver that supports two types of string replacement: (1)
replacing the first occurrence of a substring matching a given pattern, and (2)
replacing all occurrences of substrings matching a given pattern, i.e., either
a constant string or a regular expression.




%While the core solving algorithm maintains the certification guarantees of CertiStrR, the frontend components are implemented using established non-certified  OCaml libraries: dolmen \cite{dolmen} for SMT-LIB parsing and ocaml-re-nfa \cite{ocaml-re-nfa} for regular expression to NFA conversion.


% Listing \ref{lst-smtlib-code} demonstrates the regular expression variant through an example that replaces numeric sequences with the string "\texttt{NUM}". The constraints are satisfiable because the input string \texttt{a} = "\texttt{2024,2025}" contains a substring "\texttt{2025}" that matches the regular expression \texttt{re.+ (re.range "0" "9")} (equivalent to \texttt{/[0-9]+/}), and replacing this match with "\texttt{NUM}" yields the expected output string \texttt{b} = "\texttt{2024,NUM}".
% %
%
%
% \begin{lstlisting}[language=SMTLIB, caption={Example SMT-LIB Code}, label={lst-smtlib-code}, float=htbp]
%   (set-logic QF_S)
%   (declare-fun a () String)
%   (declare-fun b () String)
%   (assert (= a "2024,2025"))
%   (assert (= b "2024,NUM"))
%   (assert (= b (str.replace_re a 
%       (re.+ (re.range "0" "9")) "NUM")))
%   (check-sat)
%   \end{lstlisting}

We evaluate {CertiStrR} using benchmarks from SMT-LIB 2025~\cite{smtlib_benchmarks}, focusing on the \textsf{QF\_S} and \textsf{QF\_SLIA} logic fragments. The benchmarks are divided into two categories: (1) replace-first and (2) replace-all. In addition to replacement, the tests also include string concatenation and regular constraints. Due to the limitation of CertiStrR's front-end, some constraints were rewritten or removed from the tests.


% replace_re
% Average real time: 0.37 seconds
% Total number of real entries: 98
% Average user time: 0.35 seconds
% Total number of user entries: 98
% Average sys time: 0.01 seconds
% Total number of sys entries: 98
% Total number of SAT entries: 61
% Total number of UNSAT entries: 4
% Total number of inconclusive entries: 30

% replace_str
% Average real time: 0.27 seconds
% Total number of real entries: 323
% Average user time: 0.25 seconds
% Total number of user entries: 323
% Average sys time: 0.01 seconds
% Total number of sys entries: 323
% Total number of SAT entries: 315
% Total number of UNSAT entries: 173
% Total number of inconclusive entries: 8


%\begin{table}[h]
%  \centering
%  \small
%  \begin{tabular}{lcccc}
%      \toprule
%      & \textbf{SAT/UNSAT/Inc} & \textbf{Time (s)} & \textbf{Tests} %\\
%      \midrule
%      \texttt{replace singleton} & 142/173/8 & 0.27 & 323\\
%      \texttt{replace all} & 84/4/10 & 0.36 & 98\\
%      \bottomrule
%  \end{tabular}
%  \caption{Experimental results}
%  \label{tab:string_operations}
%\end{table}

\begin{table*}[h]
\centering
\small
\caption{Experimental results}
\label{tab:string_operations}
\setlength{\tabcolsep}{4pt}
\renewcommand{\arraystretch}{1.1}
\begin{tabular}{llccccccc}
  \toprule
  \textbf{Subgroup} & \textbf{Test} & \textbf{Count} & \textbf{SAT} & \textbf{UNSAT} & \textbf{Inconclusive} & \textbf{CertiStrR (s)} & \textbf{Ostrich (s/timeout)} & \textbf{CVC5 (s/timeout)} \\
  \midrule
  \multirow{2}{*}{Replace-First} & Replace RE  & 94  & 77  & 16  & 1 & 0.79 & 166.27/27 & 2.67/20 \\
   & Replace Str & 323 & 103 & 211 & 9 & 1.94 & 7.10/20 & 0.81/1 \\
     \midrule
  \multirow{4}{*}{Replace-All} & PCP & 1000 & 751 & 249 & 0 & 0.14 & 3.412/0 & unknown \\
   & RNA SAT   & 500  & 500 & 0   & 0 & 2.81 & 55.61/0 & unknown \\
   & RNA UNSAT & 500  & 0   & 500 & 0 & 3.14 & 64.185/0 & unknown \\
   & WebApp      & 255  & 40  & 215 & 0 & 0.79 & 23.67/17 & 8.379/1 \\
  \bottomrule
\end{tabular}
\end{table*}


The experimental evaluation was conducted on a laptop with an Apple M4 processor and 24 GB of memory, with a \textbf{one-hour} time limit per test. Table~\ref{tab:string_operations} summarizes the results. The results from CertiStrR were classified into three categories: SAT (satisfiable), indicating that there exist assignments of string variables satisfying the constraints; UNSAT (unsatisfiable), indicating that no such assignments exist; and Inconclusive. An "Inconclusive" result indicates that the solver cannot determine satisfiability due to the inherent incompleteness of the string solver's algorithm, not timeout (all tests completed within one hour). This occurs when the solver cannot determine whether string variables need to be assigned different values that satisfy all constraints. 

We also compare our approach with two state-of-the-art string solvers: Ostrich \cite{pacmpl/ChenFHHHKLRW22} and CVC5 \cite{cvc5}.
The experimental results demonstrate that string replacement operations, particularly replace-all operations, pose significant challenges for existing state-of-the-art solvers.
The "unknown" label in the table indicates the tests where CVC5 cannot determine satisfiability. 
Notably, PCP and RNA benchmarks cannot be solved by most state-of-the-art string
solvers, including CVC5 \cite{cvc5}, yet CertiStrR solves
them efficiently. Among existing solvers, only OSTRICH \cite{ostrich,pacmpl/ChenFHHHKLRW22} can handle these benchmarks.
CertiStrR outperforms both Ostrich and CVC5 across most benchmark subgroups, with the only exception of the "Replace Str" category where CVC5 achieves better performance (though it experiences one timeout). CertiStrR demonstrates particularly strong performance in  "Replace All" category.
These results demonstrate the effectiveness and efficiency of our SFT formalization and implementation.

Our approach demonstrates superior efficiency compared to other string solving approaches for several key reasons. First, our SFTs are implemented with compact symbolic labels that enable efficient representation of infinite alphabets, and we employ red-black trees for storing states, ensuring logarithmic-time lookup and insertion operations. Second, our forward propagation strategy proves more efficient than alternative approaches such as term rewriting or backpropagation employed by other solvers. While forward propagation supports only a limited set of string constraints—for instance, it is only complete for string constraints satisfy tree properties \cite{cpp/KanLRS22}—this trade-off between completeness and efficiency enables our solver to handle large-scale benchmarks that remain intractable for more general but computationally expensive approaches.



\paragraph{Transducers vs. Replacement Operations.}
Although both transducers and replacement operations can express string
transformations for security-related verification, transducers are strictly more
expressive because they can capture dependencies between the input pattern and
the replacement string. In contrast, all replacement operations in SMT-LIB treat
the pattern and the replacement string as independent. For example, in the SFT
in Figure~\ref{fig:html-sanitizer-sft}, a transition may be defined over
an interval such as $[\texttt{a-z}]$, and the output function computes its
output directly based on the input character. Replacement operations, however,
cannot express such dependencies since the replacement string is not a function.

Consider a string transformation that replace each character in $[\texttt{a-z}]$ with its ASCII code. Modeling this transformation using only replacement operations requires spliting the interval $[\texttt{a-z}]$ into individual characters, resulting in 26 separate \texttt{replace-all} operations—one for each letter. For example:
\begin{verbatim}
  replace(replace(..., b, 0x62, g), a, 0x61, g)
\end{verbatim}


When the interval contains a large set of characters—as is common in web applications that support the full Unicode range of 
\texttt{0x10FFFF} code points—this nested structure becomes impractical, leading to significant inefficiency and complexity in the replacement-based approach.


\subsection{Effort of Certified Development}

%This subsection discusses the development effort required for our certified SFT formalization. 
While SFTs constitute the central contribution of this paper, they are not sufficient on their own to support the applications we target. A more comprehensive symbolic framework for automata libraries is necessary. Beyond the existing automata library supported by CertiStr \cite{cpp/KanLRS22}, which already includes operations such as SFA product and SFA concatenation, we needed to develop additional \emph{certified} SFA operations from scratch. These include $\varepsilon$SFAs, translation from $\varepsilon$SFAs to SFAs, translation from SFAs to Symbolic Deterministic Finite Automata (SDFA), and negation of SFAs. Table~\ref{tab:abstract_impl} summarizes the certified development effort that was carried out specifically for this work.

The abstract-level development encompasses all formalizations presented in Section~\ref{sec:abstract-layer}, including SFTs and the additional SFA operations used in this paper's application. The implementation-level development covers all formalizations described in Section~\ref{sec_alg_refinement}, including the refinement of the product operation and other SFA operations used in this paper's application. The final row of Table~\ref{tab:abstract_impl} corresponds to the effort devoted to interval formalization. The most challenging component proved to be the correctness proof of the product operation at the abstract level (Figure~\ref{fig-def-product-correct}).
%
%Compared to CertiStr \cite{cpp/KanLRS22}, the interval formalization in CertiStrR is substantially more complex, primarily because intervals were extended from single pairs to lists.


\begin{table}[h]
  \centering
  \small
  \caption{Overview of the effort of certified development}
  \label{tab:abstract_impl}
  \begin{tabular}{lccc}
      \toprule
      & \textbf{Definitions} & \textbf{Lemmas} & \textbf{Proofs (LOC)} \\
      \midrule
      Abstract & 17 & 21 & 3274 \\
      Implementation & 51 & 43 & 2700 \\
      Interval & 15 & 29 & 1500 \\
      \bottomrule
  \end{tabular}
\end{table}
